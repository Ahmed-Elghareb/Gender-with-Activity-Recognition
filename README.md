# Gender-with-Activity-Recognition

## Overview

Regarding the booming of big data and HAR in the scientific world, we conducted a research project that addresses the recognition of activities performed in addition to the gender of the performer. In this work, we present two models (hierarchical model and joint distribution model) and compare between two datasets (MoVi and MotionSense), using only two IMU sensors on right and left hand and motion sense dataset using mobile phone, to predict gender with activity and see how every activity reflect on gender, and explore the efficiency on using autocorrelation function as a feature extractor and compare between three classifiers, Random Forest (RF), Support Vector Machine (SVM) and Convolution Neural Network (CNN).
The diagram below illustrates the process of data processing, model designing, and inference.  
<p align="center">
<img src="https://user-images.githubusercontent.com/61229902/170962144-66ba0511-db33-4c87-a7cd-1b8906058ed1.png" width="900" height="200" />
</p>

<!-- <p align="center">
<img src="https://user-images.githubusercontent.com/61229902/170965290-d462820d-0c0d-465b-8615-b68893f27bbb.png" width="200" height="300" />
</p> -->
Data Visualization for MoVi Data, https://www.biomotionlab.ca/movi/
<p align="center">
<img src="https://github.com/saeed1262/MoVi-Toolbox/blob/352621e742ff8f745c3ada417d3db22d0ddf31ae/demo.gif" />
</p>



It is worth to note that the cut and feature-extracted data are available upon request.
<!-- - The main.rar file includes the raw data extracted from the .mat files downloaded, while the FINAL.rar resembles the data overlapped preprocessed, and used for the training -->

